{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¨ SP1: Video Pipeline for 3D Object Detection\n",
        "\n",
        "This notebook demonstrates the **video processing capabilities** of the SP1 pipeline.\n",
        "\n",
        "## Features\n",
        "- Process video files with 3D object detection\n",
        "- Real-time webcam processing\n",
        "- Depth map visualization\n",
        "- Annotated video output\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/Zulqarnain-cc34/3d_detection.git\"\n",
        "REPO_NAME = \"3d_detection\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(\"üì• Cloning repository...\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(f\"üìÅ Repository exists. Pulling latest...\")\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "    %cd ..\n",
        "\n",
        "%cd {REPO_NAME}\n",
        "!git log -1 --oneline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install -q -r requirements.txt\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import pipeline components\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from src.pipeline import SP1Pipeline\n",
        "from src.video_pipeline import SP1VideoPipeline, VideoConfig\n",
        "\n",
        "# Select device\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Initialize the base SP1 pipeline\n",
        "print(\"\\nüöÄ Initializing SP1 Pipeline...\")\n",
        "pipeline = SP1Pipeline(device=DEVICE)\n",
        "print(\"‚úÖ Pipeline ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure video pipeline\n",
        "config = VideoConfig(\n",
        "    detection_classes=[\n",
        "        \"person\", \"chair\", \"table\", \"couch\", \"tv\", \n",
        "        \"laptop\", \"bottle\", \"cup\", \"book\", \"phone\"\n",
        "    ],\n",
        "    confidence_threshold=0.25,\n",
        "    process_every_n_frames=1,  # Process every frame (set to 2 or 3 for faster processing)\n",
        "    show_depth_minimap=True,\n",
        "    show_3d_overlay=True,\n",
        "    show_fps=True,\n",
        "    show_object_panel=True,\n",
        "    depth_colormap=\"plasma\"\n",
        ")\n",
        "\n",
        "# Create video pipeline\n",
        "video_pipeline = SP1VideoPipeline(pipeline, config)\n",
        "print(\"üé¨ Video pipeline configured!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download Sample Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# Download a sample video (indoor scene)\n",
        "# You can replace this URL with your own video\n",
        "SAMPLE_VIDEO_URL = \"https://github.com/intel-iot-devkit/sample-videos/raw/master/head-pose-face-detection-female-and-male.mp4\"\n",
        "SAMPLE_VIDEO_PATH = \"data/sample_video.mp4\"\n",
        "\n",
        "if not os.path.exists(SAMPLE_VIDEO_PATH):\n",
        "    print(\"üì• Downloading sample video...\")\n",
        "    urllib.request.urlretrieve(SAMPLE_VIDEO_URL, SAMPLE_VIDEO_PATH)\n",
        "    print(f\"‚úÖ Downloaded: {SAMPLE_VIDEO_PATH}\")\n",
        "else:\n",
        "    print(f\"üìÅ Using existing: {SAMPLE_VIDEO_PATH}\")\n",
        "\n",
        "# Show video info\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(SAMPLE_VIDEO_PATH)\n",
        "print(f\"\\nVideo properties:\")\n",
        "print(f\"  Resolution: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")\n",
        "print(f\"  FPS: {cap.get(cv2.CAP_PROP_FPS):.1f}\")\n",
        "print(f\"  Frames: {int(cap.get(cv2.CAP_PROP_FRAME_COUNT))}\")\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Process Video File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process the sample video\n",
        "INPUT_VIDEO = SAMPLE_VIDEO_PATH\n",
        "OUTPUT_VIDEO = \"outputs/detected_video.mp4\"\n",
        "\n",
        "print(f\"üé¨ Processing: {INPUT_VIDEO}\")\n",
        "print(f\"üì§ Output: {OUTPUT_VIDEO}\")\n",
        "print()\n",
        "\n",
        "# Process video (set max_frames for quick test)\n",
        "stats = video_pipeline.process_video(\n",
        "    input_path=INPUT_VIDEO,\n",
        "    output_path=OUTPUT_VIDEO,\n",
        "    max_frames=100,  # Process first 100 frames for demo (remove for full video)\n",
        "    display=False    # No display in Colab (set True for local)\n",
        ")\n",
        "\n",
        "print(f\"\\nüìä Processing Stats:\")\n",
        "print(f\"  Frames: {stats['frames_processed']}\")\n",
        "print(f\"  Detections: {stats['total_detections']}\")\n",
        "if 'avg_fps' in stats:\n",
        "    print(f\"  Avg FPS: {stats['avg_fps']:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Display Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path, width=800):\n",
        "    \"\"\"Display video in Colab notebook.\"\"\"\n",
        "    mp4 = open(video_path, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f\"\"\"\n",
        "    <video width={width} controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\")\n",
        "\n",
        "# Display the output video\n",
        "print(\"üé• Output Video with 3D Detection:\")\n",
        "show_video(OUTPUT_VIDEO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Frame-by-Frame Processing (Generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Process frames using generator\n",
        "print(\"üì∏ Processing individual frames...\\n\")\n",
        "\n",
        "frames_to_show = []\n",
        "frame_count = 0\n",
        "\n",
        "for result in video_pipeline.generate_frames(INPUT_VIDEO):\n",
        "    frame_count += 1\n",
        "    \n",
        "    # Save every 30th frame for display\n",
        "    if frame_count % 30 == 0:\n",
        "        frames_to_show.append({\n",
        "            'annotated': cv2.cvtColor(result.annotated_frame, cv2.COLOR_BGR2RGB),\n",
        "            'depth': result.depth_colormap,\n",
        "            'frame_num': result.frame_number,\n",
        "            'num_objects': len(result.detections_3d),\n",
        "            'fps': result.current_fps\n",
        "        })\n",
        "        print(f\"Frame {result.frame_number}: {len(result.detections_3d)} objects, {result.current_fps:.1f} FPS\")\n",
        "    \n",
        "    # Stop after 150 frames for demo\n",
        "    if frame_count >= 150:\n",
        "        break\n",
        "\n",
        "print(f\"\\n‚úÖ Processed {frame_count} frames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample frames\n",
        "if frames_to_show:\n",
        "    n_frames = min(len(frames_to_show), 4)\n",
        "    fig, axes = plt.subplots(n_frames, 2, figsize=(14, 4*n_frames))\n",
        "    \n",
        "    for i, frame_data in enumerate(frames_to_show[:n_frames]):\n",
        "        # Annotated frame\n",
        "        axes[i, 0].imshow(frame_data['annotated'])\n",
        "        axes[i, 0].set_title(f\"Frame {frame_data['frame_num']} | {frame_data['num_objects']} objects | {frame_data['fps']:.1f} FPS\")\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        # Depth map\n",
        "        depth_rgb = cv2.cvtColor(frame_data['depth'], cv2.COLOR_BGR2RGB)\n",
        "        axes[i, 1].imshow(depth_rgb)\n",
        "        axes[i, 1].set_title(f\"Depth Map - Frame {frame_data['frame_num']}\")\n",
        "        axes[i, 1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/frame_samples.png', dpi=150)\n",
        "    plt.show()\n",
        "    print(\"üíæ Saved: outputs/frame_samples.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Upload Your Own Video (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üì§ Upload your video file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    uploaded_file = list(uploaded.keys())[0]\n",
        "    custom_input = f\"data/{uploaded_file}\"\n",
        "    custom_output = f\"outputs/detected_{uploaded_file}\"\n",
        "    \n",
        "    # Move to data folder\n",
        "    import shutil\n",
        "    shutil.move(uploaded_file, custom_input)\n",
        "    \n",
        "    print(f\"\\nüé¨ Processing your video: {custom_input}\")\n",
        "    \n",
        "    stats = video_pipeline.process_video(\n",
        "        input_path=custom_input,\n",
        "        output_path=custom_output,\n",
        "        display=False\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Done! Output saved to: {custom_output}\")\n",
        "    show_video(custom_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Download Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the processed video\n",
        "print(\"üì• Downloading output video...\")\n",
        "files.download(OUTPUT_VIDEO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù API Reference\n",
        "\n",
        "### VideoConfig Options\n",
        "\n",
        "| Parameter | Type | Default | Description |\n",
        "|-----------|------|---------|-------------|\n",
        "| `detection_classes` | List[str] | furniture list | Object classes to detect |\n",
        "| `confidence_threshold` | float | 0.25 | Min detection confidence |\n",
        "| `process_every_n_frames` | int | 1 | Frame skip (1=all, 2=every 2nd) |\n",
        "| `show_depth_minimap` | bool | True | Show depth map corner overlay |\n",
        "| `show_3d_overlay` | bool | True | Show 3D detection boxes |\n",
        "| `show_fps` | bool | True | Show FPS counter |\n",
        "| `show_object_panel` | bool | True | Show object list panel |\n",
        "| `depth_colormap` | str | \"plasma\" | Colormap: plasma, viridis, magma, jet |\n",
        "| `output_fps` | float | 30.0 | Output video FPS |\n",
        "\n",
        "### SP1VideoPipeline Methods\n",
        "\n",
        "```python\n",
        "# Process video file\n",
        "stats = video_pipeline.process_video(\n",
        "    input_path='input.mp4',\n",
        "    output_path='output.mp4',\n",
        "    max_frames=None,      # None = all frames\n",
        "    display=True,         # Show live preview\n",
        "    callback=None         # Optional: callback(FrameResult) -> bool\n",
        ")\n",
        "\n",
        "# Run on webcam\n",
        "stats = video_pipeline.run_webcam(\n",
        "    camera_id=0,\n",
        "    output_path='webcam_output.mp4'  # Optional\n",
        ")\n",
        "\n",
        "# Generator for custom processing\n",
        "for result in video_pipeline.generate_frames('video.mp4'):\n",
        "    # result.annotated_frame - BGR frame with overlays\n",
        "    # result.depth_colormap - Depth visualization\n",
        "    # result.detections_3d - List of BoundingBox3D\n",
        "    pass\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
