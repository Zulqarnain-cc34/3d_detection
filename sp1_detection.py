# -*- coding: utf-8 -*-
"""sp1_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ckxjD_c1XtcCHJh6_PaHs3dNiA571DEO

# ü§ñ SP1: 3D Open-Vocabulary Object Detection Pipeline

**Testing Notebook for GitHub Repository**

This notebook clones and tests the SP1 pipeline from:
- **Repository**: https://github.com/Zulqarnain-cc34/3d_detection

---

## ‚ö° Quick Start
1. Run **Section 1** to setup (clone repo + install)
2. Run **Section 2** to test the pipeline
3. If you push changes to GitHub, run **Section 1.2** to pull latest

---

# 1. Setup Environment

### 1.0 Check GPU (Optional but Recommended)
Go to **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**
"""

# Check if GPU is available
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
else:
    print("‚ö†Ô∏è No GPU detected. Pipeline will run on CPU (slower).")

"""### 1.1 Clone Repository (Run Once)"""

# Commented out IPython magic to ensure Python compatibility.
import os

# Repository URL
REPO_URL = "https://github.com/Zulqarnain-cc34/3d_detection.git"
REPO_NAME = "3d_detection"

# Clone if not exists
if not os.path.exists(REPO_NAME):
    print("üì• Cloning repository...")
    !git clone {REPO_URL}
    print("‚úÖ Repository cloned!")
else:
    print(f"üìÅ Repository '{REPO_NAME}' already exists.")
    print("   Run the next cell (1.2) to pull latest changes.")

# Change to repo directory
# %cd {REPO_NAME}

# Show current commit
print("\nüìå Current commit:")
!git log -1 --oneline

"""### 1.2 Pull Latest Changes (Run After Each GitHub Push) üîÑ"""

# Commented out IPython magic to ensure Python compatibility.
# ===================================================
# üîÑ RUN THIS CELL AFTER YOU PUSH CHANGES TO GITHUB
# ===================================================

import os
REPO_NAME = "3d_detection"

# Make sure we're in the repo directory
if os.path.basename(os.getcwd()) != REPO_NAME:
#     %cd /content/{REPO_NAME}

print("üì• Pulling latest changes from GitHub...")
!git fetch origin
!git reset --hard origin/main  # Use 'master' if your branch is named master

print("\n‚úÖ Updated to latest commit:")
!git log -1 --oneline

print("\nüìÅ Repository contents:")
!ls -la

"""### 1.3 Install Dependencies"""

# Install required packages
print("üì¶ Installing dependencies...")

!pip install -r /content/3d_detection/requirements.txt

# Explicitly upgrade ultralytics to ensure latest device handling fixes
print("‚¨ÜÔ∏è Upgrading ultralytics...")
!pip install ultralytics --upgrade

print("‚úÖ Dependencies installed and ultralytics upgraded!")

"""### 1.4 Import Pipeline"""

# Commented out IPython magic to ensure Python compatibility.
import sys
import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import requests
from io import BytesIO

# Add src to Python path
REPO_NAME = "3d_detection"
if os.path.basename(os.getcwd()) != REPO_NAME:
#     %cd /content/{REPO_NAME}

# Reload modules if already imported (for when you pull updates)
if 'src' in sys.modules:
    import importlib
    import src
    importlib.reload(src)
    from src import pipeline, detector, depth_estimator, projector, visualizer
    importlib.reload(pipeline)
    importlib.reload(detector)
    importlib.reload(depth_estimator)
    importlib.reload(projector)
    importlib.reload(visualizer)
    print("üîÑ Modules reloaded!")

# Import pipeline components
from src import SP1Pipeline, PipelineVisualizer

print("‚úÖ Imports successful!")

"""---
# 2. Test Pipeline

### 2.1 Initialize Pipeline
"""

import torch

# Auto-detect device
DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è Using device: {DEVICE}")

# Initialize pipeline
print("\n" + "="*60)
print("Initializing SP1 3D Detection Pipeline")
print("="*60)
pipeline = SP1Pipeline(
    detector_model='yolov8s-world',
    device='cuda:0',
    confidence_threshold=0.25,
    min_depth=0.5,
    max_depth=10.0
)

# CUDA-FIX: Ensure all sub-models are on GPU (CORRECTED)
pipeline.detector.model.to('cuda:0')
torch.cuda.empty_cache()
print(f"‚úÖ Detector forced to CUDA:0 | GPU Memory: {torch.cuda.memory_allocated()/1e9:.1f}GB")
print("Pipeline initialized successfully!")

"""### 2.2 Load Test Image"""

# Download sample indoor scene image
IMAGE_URL = "https://images.unsplash.com/photo-1586023492125-27b2c045efd7?w=800"

print("üì• Downloading test image...")
response = requests.get(IMAGE_URL)
image = Image.open(BytesIO(response.content)).convert('RGB')
image_np = np.array(image)

print(f"‚úÖ Image loaded: {image_np.shape}")

# Display image
plt.figure(figsize=(12, 8))
plt.imshow(image_np)
plt.title("Test Image: Indoor Room Scene", fontsize=14)
plt.axis('off')
plt.show()

"""### 2.3 Run 3D Object Detection"""

# Define objects to detect (open-vocabulary!)
QUERY_CLASSES = [
    "chair", "sofa", "table", "lamp",
    "tv", "door", "window", "plant", "pillow"
]

print(f"üîç Searching for: {QUERY_CLASSES}")
print("\n‚è≥ Running pipeline...")

# Run detection
result = pipeline.detect(image_np, QUERY_CLASSES)

# Print summary
print("\n" + result.summary())

"""### 2.4 Visualize Results"""

# Create comprehensive visualization
viz = PipelineVisualizer()

fig = viz.visualize_pipeline_result(
    image=image_np,
    detections_2d=result.detections_2d,
    depth_result=result.depth_result,
    detections_3d=result.detections_3d,
    title=f"SP1 3D Detection - {len(result.detections_3d)} Objects Found"
)

plt.show()

"""### 2.5 Detailed 3D Results"""

print("=" * 60)
print("DETAILED 3D DETECTION RESULTS")
print("=" * 60)

for i, det in enumerate(result.detections_3d):
    print(f"\n[{i+1}] {det.class_name.upper()}")
    print(f"    Confidence: {det.confidence:.2%}")
    print(f"    3D Position: X={det.center[0]:.2f}m, Y={det.center[1]:.2f}m, Z={det.center[2]:.2f}m")
    print(f"    Dimensions:  W={det.dimensions[0]:.2f}m, H={det.dimensions[1]:.2f}m, D={det.dimensions[2]:.2f}m")
    print(f"    Distance from camera: {det.center[2]:.2f} meters")

if not result.detections_3d:
    print("\n‚ùå No objects detected. Try lowering confidence threshold.")

"""### 2.6 Navigation Waypoint Test"""

import torch

# Test waypoint generation for robot navigation
TARGET_OBJECT = "sofa"  # Change this to test different objects

print(f"üéØ Generating navigation waypoint to: '{TARGET_OBJECT}'")

# Explicitly ensure the detector model and its internal CLIP model are on the correct device
if hasattr(pipeline, 'detector') and hasattr(pipeline.detector, 'model'):
    # Check and move the main YOLO model if necessary

    if pipeline.detector.model.device != torch.device(DEVICE):
        print(f"üîÑ Moving main detector model from {pipeline.detector.model.device} to {DEVICE}...")
        pipeline.detector.model.to(DEVICE)

    # Check and move the internal CLIP text encoder (used by YOLO-World) if necessary
    # The exact attribute name might vary slightly between ultralytics versions
    if hasattr(pipeline.detector.model.model, 'text_encoder') and pipeline.detector.model.model.text_encoder is not None:
        if pipeline.detector.model.model.text_encoder.device != torch.device(DEVICE):
            print(f"üîÑ Moving YOLO-World text encoder from {pipeline.detector.model.model.text_encoder.device} to {DEVICE}...")
            pipeline.detector.model.model.text_encoder.to(DEVICE)
    elif hasattr(pipeline.detector.model.model, 'clip_model') and pipeline.detector.model.model.clip_model is not None: # Fallback for older versions
        if pipeline.detector.model.model.clip_model.device != torch.device(DEVICE):
            print(f"üîÑ Moving YOLO-World clip_model from {pipeline.detector.model.model.clip_model.device} to {DEVICE}...")
            pipeline.detector.model.model.clip_model.to(DEVICE)
    else:
        print("‚ö†Ô∏è Could not find internal text encoder/CLIP model to explicitly move to device. Proceeding anyway.")

waypoint = pipeline.get_waypoint(
    image_np,
    target_object=TARGET_OBJECT,
    offset_distance=0.5  # Stop 0.5m from object
)

if waypoint:
    print(f"\n‚úÖ Waypoint generated!")
    print(f"   Object position:  {[f'{x:.2f}' for x in waypoint['object_position']]} meters")
    print(f"   Waypoint (stop):  {[f'{x:.2f}' for x in waypoint['waypoint_position']]} meters")
    print(f"   Distance to obj:  {waypoint['distance_to_object']:.2f} meters")
    print(f"   Confidence:       {waypoint['confidence']:.2%}")
else:
    print(f"\n‚ùå '{TARGET_OBJECT}' not found in scene")